# Go AI Agent

[![Go Version](https://img.shields.io/badge/Go-1.22+-00ADD8?style=flat&logo=go)](https://go.dev/)
[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)

Production-ready AI Agent framework in Go. Features ReAct pattern, Function Calling, RAG with pgvector, and multi-LLM support (OpenAI/Claude). Clean Architecture + K8s ready.

## ğŸ¯ Why Go for AI Agents?

- **Performance**: Low latency tool execution with Go's concurrency model
- **Differentiation**: Stand out in the Python-dominated AI landscape
- **Production Quality**: Leverage Go's reliability for enterprise deployments
- **Full Stack Integration**: Seamlessly connect with existing Go microservices

## ğŸ—ï¸ Architecture

```
go-ai-agent/
â”œâ”€â”€ cmd/
â”‚   â””â”€â”€ server/              # Application entry point
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ config/              # Configuration management
â”‚   â”œâ”€â”€ llm/                 # LLM client abstraction
â”‚   â”‚   â”œâ”€â”€ client.go        # Client interface
â”‚   â”‚   â””â”€â”€ openai.go        # OpenAI implementation
â”‚   â”œâ”€â”€ handler/             # HTTP handlers
â”‚   â”œâ”€â”€ agent/               # ReAct agent (coming soon)
â”‚   â””â”€â”€ tools/               # Function calling tools (coming soon)
â”œâ”€â”€ pkg/
â”‚   â””â”€â”€ middleware/          # Shared middleware
â””â”€â”€ deploy/                  # Deployment manifests (coming soon)
```

## ğŸš€ Quick Start

### Prerequisites

- Go 1.22+
- OpenAI API key

### Installation

```bash
# Clone the repository
git clone https://github.com/hassan123789/go-ai-agent.git
cd go-ai-agent

# Install dependencies
go mod download

# Copy and edit environment variables
cp .env.example .env
# Edit .env with your OpenAI API key
```

### Running

```bash
# Run the server
make run

# Or directly with Go
go run ./cmd/server
```

### API Usage

```bash
# Health check
curl http://localhost:8080/health

# Chat completion
curl -X POST http://localhost:8080/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [
      {"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "Hello, how are you?"}
    ]
  }'

# Streaming response
curl -X POST http://localhost:8080/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [{"role": "user", "content": "Tell me a joke"}],
    "stream": true
  }'
```

## ğŸ› ï¸ Development

```bash
# Run tests
make test

# Run linter
make lint

# Format code
make fmt

# Pre-push checks
make pre-push
```

## ğŸ“‹ Roadmap

- [x] **Phase 1**: LLM Client & Basic Chat API
- [ ] **Phase 2**: Function Calling & Tool Integration
- [ ] **Phase 3**: ReAct Agent Pattern
- [ ] **Phase 4**: RAG with pgvector
- [ ] **Phase 5**: Multi-LLM Support (Claude, local models)
- [ ] **Phase 6**: Kubernetes Deployment

## ğŸ§ª Features

### Current (v0.1)

- âœ… OpenAI Chat Completion
- âœ… Streaming Responses (SSE)
- âœ… Clean Architecture
- âœ… Configuration Management
- âœ… Graceful Shutdown

### Coming Soon

- ğŸ”„ Function Calling
- ğŸ”„ ReAct Agent Pattern
- ğŸ”„ Conversation Memory
- ğŸ”„ Vector Store (pgvector)
- ğŸ”„ gRPC API
- ğŸ”„ Kubernetes Manifests

## ğŸ“Š Tech Stack

| Category | Technology |
|----------|-----------|
| Language | Go 1.22+ |
| HTTP Framework | Echo v4 |
| LLM Client | sashabaranov/go-openai |
| Vector DB | pgvector (planned) |
| Deployment | Kubernetes (planned) |

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
